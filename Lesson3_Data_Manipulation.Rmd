---
title: 'Lesson 3: Data Manipulation'
author: "Matt Clark"
date: "11/25/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Introduction
There is a common misconception that analyzing data and modeling are time consuming and difficult to do. In reality, analyzing data is the easy part of doing science. Often times the most difficult part of a research project is manipulating and cleaning your data so it is ready for analysis. In this lesson, we will go over how to simple data manipulation/cleaning using the `dplyr` and `tidyr` packages. Both of these packages are also part of the `tidyverse` suite of packages which contains the `ggplot2` package which we used during the last lesson.

In this lesson, we will go over.

1. Recoding data
2. Subsetting dataframes
3. Data processing through piping 
4. Grouping by a categorical variable
5. Creating functions to speed up repetitive tasks
6. Changing data between long and wide formats

# Learning Objectives
* Students can recode categorical values and column names
* Students understand the utility and can make use of pipes
* Students know general `dplyr` functions and can write code using them
* Students can create simple functions
* Students can manipulate data from long to wide.

# Content

First let's load the packages we will use during this lesson

```{r}
library(tidyverse)
```

Now let's load the data
Keep in mind that your file path will likely be different than the file path shown below

```{r}
dat<-read_csv("~/Kinesiology_Teaching/Data/Manuscript_Data.csv")
```

Let's make a dummy `Treatment' variable that we will use for our facets.

We're going to imagine that each of our 36 participants got either `Treatment` A, B, C, or D.

```{r}
dat$Treatment<-c(rep("A",9),rep("B",9),rep("C",9),rep("D",9))
```

### Recoding data

Let's check what kind of variable our "Sex" data is being read as

How do we want this to be read?

```{r}
typeof(dat$Sex)
```


Check what the values are

```{r}
unique(dat$Sex)
```

Is this how we should be reading `Sex` data for analyses?

Probably not!

Likely we want `Sex` to be a categorical variable that has the values Male or Female.

There are __MANY__ ways to change this.

Here we will show you a particularly easy one from the `dplyr` package

```{r}
dat$Sex<-as.character(dat$Sex)
```


Let's Check that that did what we want it to do

Note that below we call `dplyr::` before we run the `recode` function. We don't have to do this, but it's good practice if your function also exists within other packages.

```{r}
dplyr::recode(dat$Sex, "1" = "Male", "2" = "Female", .default = NA_character_)
```

Great, that's working!
Now let's actually change our `Sex` vector (column) in our dataframe

```{r}
dat$Sex<-dplyr::recode(dat$Sex, "1" = "Male", "2" = "Female", .default = NA_character_)
```


Lets also rename some of the quantitative variables in our dataframe so that they are easier to deal with

```{r}
names(dat)[3]<-"Variable_1"
names(dat)[4]<-"Variable_2"
```


### Subsetting dataframes


Lets make it a bit more simple and only include the columns we want. 

We will do this using `dplyr`

```{r}
dat_simple<-select(dat, Subject,Sex,Variable_1,Variable_2,Treatment)
```

### Data processing through piping 

You can imagine that if we had more than 1 function, nesting them could be quite cumbersome. To get around this, we can use pipes!

```{r}
dat_simple<-dat%>%
  select(Subject,Sex,Variable_1,Variable_2,Treatment)
```


Imagine we wanted to do the same subsetting above, but also filter by a variable

```{r}
dat_simple_female<-dat%>%
  select(Subject,Sex,Variable_1,Variable_2,Treatment)%>%
  filter(Sex == "Female")
```


__CHALLENGE 1__
Write a single command (which can span multiple lines and includes pipes) that will produce a dataframe that has the male values for only `Treatment` & `Subject`.


Here's the solution. 
Note that the order of `filter` and `select` must be switched from before.

```{r}

dat_Challenge_1<-dat%>%
  filter(Sex == "Male")%>%
  select(Subject,Treatment)
```


__CHALLENGE 2__
Write a single command (which can span multiple lines and includes pipes) that will produce a dataframe that has the values from treatments C & D, where Variable_2 is above 45 and contains just the treatment and variable2 columns.  

Note the OR `|` operator and the `%in%` operator.


There are two potential solutions to this challenge. 
```{r}
dat_Challenge_2<-dat%>%
  filter(Treatment %in% c("C","D"))%>%
  filter(Variable_2 > 45)%>%
  select(Variable_2,Treatment)
```

and 

```{r}
dat_Challenge_2<-dat%>%
  filter(Treatment == "C" | Treatment == "D")%>%
  filter(Variable_2 > 30)%>%
  select(Variable_2,Treatment)
```


### Grouping by a categorical variable


Let's look at grouping by different variables.
Imagine that we wanted to find the mean of `Variable_2` for each `Treatment`.

Remember that we can find the mean of a vector with the `mean()` function.

```{r}
mean(dat_simple$Variable_2)
```


Now let's do this by treatment.
Note that the `mean_Var_2 =` call just names your summarized variable.

```{r}
dat_simple%>%
  group_by(Treatment)%>%
  summarize(mean_Var_2 = mean(Variable_2))
```


__CHALLENGE 3__
Do the same thing, but get the median of Variable 1 for males and females.

```{r}
dat_simple%>%
  group_by(Sex)%>%
  summarize(med_Var_1 = median(Variable_1))
```


This is cool, but we can do tons of stuff all at the same time

```{r}
dat_simple%>%
  group_by(Treatment)%>%
  summarize(mean_Var1 = mean(Variable_1),
            sd_Var1 = sd(Variable_1),
            mean_Var2 = mean(Variable_2),
            sd_Var2 = sd(Variable_2))
```


A common thing you might want to do with your data is count things. We can do this with dplyr.

```{r}
dat_simple %>%
  filter(Variable_2 >= 45) %>%
  count(Treatment, sort = TRUE)
```

Notice that the count produces an `n` for us? This is useful, it can be used even without calling "count." One reason we might want to use the number of observations is to calculate the standard error.


```{r}
dat_simple %>%
  group_by(Treatment) %>%
  summarize(se_Var2 = sd(Variable_2)/sqrt(n()))
```



### Creating functions to speed up repetitive tasks


You could imagine that processes like this could get repetitive if you wanted to do this to a ton of datasets or a ton of variables within a dataset. One common way to make repetitive tasks faster is to create functions. Let's look at a simple example first.

```{r}
fahr_to_kelvin <- function(temp) {
  kelvin <- ((temp - 32) * (5 / 9)) + 273.15
  return(kelvin)
}
```

__CHALLENGE 4__
Write a function called kelvin_to_Celsius() that takes a temperature in Kelvin and returns that temperature in Celsius.

Hint: To convert from Kelvin to Celsius you subtract 273.15

__CHALLENGE 5__
Now go straight from far to celc. Combine the previous two functions.

```{r}
fahr_to_celsius <- function(temp) {
  temp_k <- fahr_to_kelvin(temp)
  result <- kelvin_to_celsius(temp_k)
  return(result)
}
```

Ok, now that we know how to make a function, let's do it with our data.

Lets make a function which will calculate and display the standard error of any given variable.

```{r}
zzz<-function(dat, Variable_2 , Treatment){
  require("dplyr")
  x<-dat %>%
    dplyr::group_by(dat$Treatment)%>%
    dplyr::summarize(se_Var2 = sd(dat$Variable_2)/sqrt(n()))
  return(x)
}
```

Now let's test it.

```{r}
zzz(dat=dat_simple,Variable_2,Treatment)
```


### Changing data between long and wide formats


Now let's look at a super common....and super annoying problem

Long data......

First, our data is already in a beautiful wide format..
Let's mess it up

```{r}
library(tidyr)
data_long <- gather(dat_simple, Measurment, Value, Sex:Treatment, factor_key=TRUE)
```

Ok, so this is a common way that people output data and it's the worst thing ever for analysis.

Why is this not good for analysis?


This might seem really simple, but it can cause you days of pulling out your hair. Knowing that these functions exist can save you a ton of time.

```{r}
data_wide <- spread(data_long, Measurment, Value)
```

